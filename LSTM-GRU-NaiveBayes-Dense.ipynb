{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Copy of LSTM_(1)_(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNKTUVYqCTdD"
      },
      "source": [
        "Importing Imdb Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNmzEaHZxR5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7cdf45-6281-4b87-bb85-b466ec752caf"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras import models, layers, optimizers, datasets, utils, losses\n",
        "import numpy as np\n",
        "\n",
        "vocabulary_size = 10000\n",
        "maxlen = 40\n",
        "batch_size = 25\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=vocabulary_size)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen)\n",
        "x_train\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  22,   21,  134, ...,   19,  178,   32],\n",
              "       [ 152,  491,   18, ...,   16,  145,   95],\n",
              "       [  23,   22,   12, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [ 234, 2766,  234, ...,    4, 3586,    2],\n",
              "       [  14,  123,    5, ...,   12,    9,   23],\n",
              "       [1468,    2,  497, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8Nfpoc0BOZa"
      },
      "source": [
        "PART 1 : LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fmHJ5i7NxR5Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f89c7fd4-60cd-4533-e3ab-2e69b9aa727e"
      },
      "source": [
        "inputs = layers.Input(shape=(maxlen,))\n",
        "e=layers.Embedding(vocabulary_size, 128)(inputs)\n",
        "h=layers.LSTM(128, dropout=0.8, recurrent_dropout=0.8)(e)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(h)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=4,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1000/1000 [==============================] - 137s 137ms/step - loss: 0.5278 - accuracy: 0.7283 - val_loss: 0.4369 - val_accuracy: 0.7989\n",
            "Epoch 2/4\n",
            "1000/1000 [==============================] - 136s 136ms/step - loss: 0.4067 - accuracy: 0.8151 - val_loss: 0.4476 - val_accuracy: 0.7973\n",
            "Epoch 3/4\n",
            "1000/1000 [==============================] - 135s 135ms/step - loss: 0.3625 - accuracy: 0.8390 - val_loss: 0.4169 - val_accuracy: 0.8147\n",
            "Epoch 4/4\n",
            "1000/1000 [==============================] - 135s 135ms/step - loss: 0.3261 - accuracy: 0.8565 - val_loss: 0.4481 - val_accuracy: 0.8054\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.4481 - accuracy: 0.8054\n",
            "Test accuracy: 0.805400013923645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDgQL8_EBY4m"
      },
      "source": [
        "GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhzVYpVTxR5R",
        "outputId": "9c547209-f13d-4686-9c5e-3677a2154b2d"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras import models, layers, optimizers, datasets, utils, losses\n",
        "\n",
        "vocabulary_size = 10000\n",
        "maxlen = 40\n",
        "batch_size = 25\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=vocabulary_size)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen)\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "e=layers.Embedding(vocabulary_size, 128)(inputs)\n",
        "h=layers.GRU(128, dropout=0.8, recurrent_dropout=0.8)(e)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(h)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=4,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1000/1000 [==============================] - 45s 45ms/step - loss: 0.5452 - accuracy: 0.7102 - val_loss: 0.4299 - val_accuracy: 0.8057\n",
            "Epoch 2/4\n",
            "1000/1000 [==============================] - 38s 38ms/step - loss: 0.4118 - accuracy: 0.8125 - val_loss: 0.4463 - val_accuracy: 0.8022\n",
            "Epoch 3/4\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3638 - accuracy: 0.8403 - val_loss: 0.4079 - val_accuracy: 0.8129\n",
            "Epoch 4/4\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.3292 - accuracy: 0.8581 - val_loss: 0.4074 - val_accuracy: 0.8140\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4074 - accuracy: 0.8140\n",
            "Test accuracy: 0.8140400052070618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dTWqHlCBatB"
      },
      "source": [
        "Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnTRzFR2xR5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68e88f7-5387-41ff-ea4c-1eb9882fa9c0"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras import models, layers, optimizers, datasets, utils, losses\n",
        "\n",
        "vocabulary_size = 10000\n",
        "maxlen = 40\n",
        "batch_size = 25\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=vocabulary_size)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen)\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "e=layers.Embedding(vocabulary_size, 128)(inputs)\n",
        "h=layers.Dense(128, activation = \"relu\" )(e)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(h)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=4,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1000/1000 [==============================] - 22s 22ms/step - loss: 0.6797 - accuracy: 0.5520 - val_loss: 0.6774 - val_accuracy: 0.5562\n",
            "Epoch 2/4\n",
            "1000/1000 [==============================] - 22s 22ms/step - loss: 0.6728 - accuracy: 0.5641 - val_loss: 0.6780 - val_accuracy: 0.5553\n",
            "Epoch 3/4\n",
            "1000/1000 [==============================] - 22s 22ms/step - loss: 0.6712 - accuracy: 0.5662 - val_loss: 0.6790 - val_accuracy: 0.5581\n",
            "Epoch 4/4\n",
            "1000/1000 [==============================] - 22s 22ms/step - loss: 0.6705 - accuracy: 0.5669 - val_loss: 0.6785 - val_accuracy: 0.5578\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6785 - accuracy: 0.5578\n",
            "Test accuracy: 0.5577547550201416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yagipqkEBdOM"
      },
      "source": [
        "Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51lub4iMxR5R",
        "outputId": "7e540134-bc17-4d89-d832-ce49f6c39bf0"
      },
      "source": [
        "# Naive Bayes\n",
        "from keras.preprocessing import sequence\n",
        "from keras import models, layers, optimizers, datasets, utils, losses\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "vocabulary_size = 10000\n",
        "maxlen = 40\n",
        "batch_size = 25\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=vocabulary_size)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen)\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "e=layers.Embedding(vocabulary_size, 128)(inputs)\n",
        "h=GaussianNB()\n",
        "# outputs=layers.Dense(1, activation='sigmoid')(h)\n",
        "# model = models.Model(inputs, outputs)\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "h.fit(x_train, y_train,)\n",
        "\n",
        "acc = h.score(x_test, y_test)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.51028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yzPpIfV12cE",
        "outputId": "6b86ed71-2d73-4ab2-fac4-84026fede4c1"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  22,   21,  134,  476,   26,  480,    5,  144,   30, 5535,   18,\n",
              "         51,   36,   28,  224,   92,   25,  104,    4,  226,   65,   16,\n",
              "         38, 1334,   88,   12,   16,  283,    5,   16, 4472,  113,  103,\n",
              "         32,   15,   16, 5345,   19,  178,   32], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-snj2LX5vzS",
        "outputId": "b9b86e1e-2cf2-4d5e-a0fb-8ba25d29b8da"
      },
      "source": [
        "x_train[0][5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "480"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oWTTazzBh-V"
      },
      "source": [
        "Picking three words from vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKUednsi3h3W",
        "outputId": "446b30ed-51b1-41c9-b04d-1a94cb487949"
      },
      "source": [
        "\n",
        "imdb = datasets.imdb\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkqGAzOh5_bc",
        "outputId": "7f6aa213-12d0-4a29-fdce-d9556e716a26"
      },
      "source": [
        "x_train[0][9]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5535"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDgDBOj733gh"
      },
      "source": [
        "review1 = [reverse_word_index.get(i-3, \"?\") for i in x_train[2]]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft9DaYm639m2",
        "outputId": "a6abec0f-ea61-456c-a2c2-a2354d2440a4"
      },
      "source": [
        "review1"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['on',\n",
              " 'film',\n",
              " 'it',\n",
              " 'looks',\n",
              " 'like',\n",
              " 'no',\n",
              " 'one',\n",
              " 'in',\n",
              " 'the',\n",
              " 'film',\n",
              " 'has',\n",
              " 'a',\n",
              " 'clue',\n",
              " 'what',\n",
              " 'is',\n",
              " 'going',\n",
              " 'on',\n",
              " 'crap',\n",
              " 'acting',\n",
              " 'crap',\n",
              " 'costumes',\n",
              " 'i',\n",
              " \"can't\",\n",
              " 'get',\n",
              " 'across',\n",
              " 'how',\n",
              " '?',\n",
              " 'this',\n",
              " 'is',\n",
              " 'to',\n",
              " 'watch',\n",
              " 'save',\n",
              " 'yourself',\n",
              " 'an',\n",
              " 'hour',\n",
              " 'a',\n",
              " 'bit',\n",
              " 'of',\n",
              " 'your',\n",
              " 'life']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "58ramfbn5qRM",
        "outputId": "cc851002-cdfd-4a39-82d6-a8f6bb5b9f85"
      },
      "source": [
        "review1[3]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'looks'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9Gs5EuEz57kT",
        "outputId": "fbf37057-85c9-4887-c209-a311dc302092"
      },
      "source": [
        "review1[30]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'watch'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXuVGRTN4SdG",
        "outputId": "bf423136-d2de-4031-cf0c-a74de383a639"
      },
      "source": [
        "x_train[7][19]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1916"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ey1eIfwWdVM",
        "outputId": "5a072b7c-dbdb-4ade-eb21-e5503999d875"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJlumkx74WLP"
      },
      "source": [
        "\n",
        "review2= [reverse_word_index.get(i-3, \"?\") for i in x_train[7]]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GOHNsG6_4bS5",
        "outputId": "727c57f2-5fb2-4ffb-e9ef-a5b5f5cc57d1"
      },
      "source": [
        "review2[7]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'never'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfJKAgXCBp5A"
      },
      "source": [
        "Calculating pairwise eucleadian distance for Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hYuEeJZZ52R",
        "outputId": "dccfc08c-0f71-4ea3-d320-122d4abcf1d8"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras import models, layers, optimizers, datasets, utils, losses\n",
        "\n",
        "vocabulary_size = 10000\n",
        "maxlen = 40\n",
        "batch_size = 25\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=vocabulary_size)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen)\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "e =layers.Embedding(vocabulary_size, 128)(inputs)\n",
        "emb=layers.Flatten()(e)\n",
        "h=layers.Dense(128, activation = \"relu\" )(emb)\n",
        "outputs=layers.Dense(1, activation='sigmoid',)(h)\n",
        "model = models.Model(inputs, outputs = [outputs,emb])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "# score, acc = model.evaluate(x_test, y_test,\n",
        "#                             batch_size=batch_size)\n",
        "# print('Test accuracy:', acc)\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 31s 31ms/step - loss: 4.2699 - dense_14_loss: 0.4950 - flatten_8_loss: 3.7749 - dense_14_accuracy: 0.7474 - flatten_8_accuracy: 3.2000e-04 - val_loss: 3.7736 - val_dense_14_loss: 0.4235 - val_flatten_8_loss: 3.3501 - val_dense_14_accuracy: 0.8000 - val_flatten_8_accuracy: 2.8000e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2951f37dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cOgqUHtlymt"
      },
      "source": [
        " y_pred = model.predict(x_train)\n",
        " emb1 = y_pred[1][2]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZHcQfCq139x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuqOYaBJYAJs",
        "outputId": "07724c44-1b59-4434-f2f7-b84d11b9f083"
      },
      "source": [
        "y_pred[1].shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 5120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx5lj9lSn76M"
      },
      "source": [
        "emb1 = emb1.reshape(40,128)\n",
        "emb_looks = emb1[3]\n",
        "emb_watch = emb1[30]"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNJ15X6cpHQ7"
      },
      "source": [
        " emb2 = y_pred[1][7]\n",
        " emb2 = emb2.reshape(40,128)\n",
        " emb_never = emb1[7]"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAJR8jAAoya0",
        "outputId": "65c25d2b-4b50-4809-f950-cc16b457fda8"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "d1 = distance.euclidean(emb_looks, emb_watch)\n",
        "print(d1)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9677779674530029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgB3bBu0pTt3",
        "outputId": "45f94579-fae9-47d5-c816-8c6bdc2baa5d"
      },
      "source": [
        "d2 = distance.euclidean(emb_looks, emb_never)\n",
        "d2"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0376962423324585"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVJNTXiKpfIU",
        "outputId": "1750fcd0-84a5-44f8-8b59-ee93a01c2407"
      },
      "source": [
        "d2 = distance.euclidean(emb_never, emb_watch)\n",
        "d2"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9602898359298706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJtusBCfBwcG"
      },
      "source": [
        "Calculating pairwise eucleadian dist for GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAlEP122ptqg",
        "outputId": "67526b00-a01f-4f58-c085-8548a62e4149"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras import models, layers, optimizers, datasets, utils, losses\n",
        "\n",
        "vocabulary_size = 10000\n",
        "maxlen = 40\n",
        "batch_size = 25\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=vocabulary_size)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen)\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "e=layers.Embedding(vocabulary_size, 128)(inputs)\n",
        "emb=layers.Flatten()(e)\n",
        "h=layers.GRU(128, dropout=0.8, recurrent_dropout=0.8)(e)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(h)\n",
        "model = models.Model(inputs, outputs=[outputs,emb])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          \n",
        "          epochs=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "# score, acc = model.evaluate(x_test, y_test,\n",
        "#                             batch_size=batch_size)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 133s 133ms/step - loss: 4.1666 - dense_16_loss: 0.5679 - flatten_10_loss: 3.5986 - dense_16_accuracy: 0.6894 - flatten_10_accuracy: 0.0000e+00 - val_loss: 3.4908 - val_dense_16_loss: 0.4274 - val_flatten_10_loss: 3.0634 - val_dense_16_accuracy: 0.8008 - val_flatten_10_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2932114a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA-xOkJoqNkW"
      },
      "source": [
        " y_pred = model.predict(x_train)\n",
        " emb1 = y_pred[1][0]"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGObqO3YfPBv"
      },
      "source": [
        "emb1 = emb1.reshape(40,128)\n",
        "emb_looks = emb1[3]\n",
        "emb_watch = emb1[30]"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwSX9efvfQ9y"
      },
      "source": [
        " emb2 = y_pred[1][7]\n",
        " emb2 = emb2.reshape(40,128)\n",
        " emb_never = emb1[7]"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vAvok7FfhA3"
      },
      "source": [
        "emb1 = emb1.reshape(40,128)\n",
        "emb_amazing = emb1[5]\n",
        "emb_praised = emb1[9]"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pNK8DOMfqth",
        "outputId": "322b03ef-7a44-43c6-bcc0-90ec34d5e4b6"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "d1 = distance.euclidean(emb_looks, emb_watch)\n",
        "print(d1)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8758007287979126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESHclMqOc3Un",
        "outputId": "f2a4e4b3-6a9c-4abf-caf8-2d271b3d4f40"
      },
      "source": [
        "d2 = distance.euclidean(emb_looks, emb_never)\n",
        "d2"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.059356451034546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCArJw9y5oHV",
        "outputId": "efe22ba6-27cb-4d16-8eba-f0d17d26ae09"
      },
      "source": [
        "d2 = distance.euclidean(emb_never, emb_watch)\n",
        "d2"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.057469367980957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7qSVsrACH63"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spxDpMGcCEqn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCHJA1_5BzmU"
      },
      "source": [
        "Calculating pairwise eucleadian distance for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBDYSIdn70-S",
        "outputId": "ac4654c6-5833-43d8-bb93-01e1fa157102"
      },
      "source": [
        "inputs = layers.Input(shape=(maxlen,))\n",
        "e=layers.Embedding(vocabulary_size, 128)(inputs)\n",
        "emb=layers.Flatten()(e)\n",
        "h=layers.LSTM(128, dropout=0.8, recurrent_dropout=0.8)(e)\n",
        "outputs=layers.Dense(1, activation='sigmoid')(h)\n",
        "model = models.Model(inputs, outputs=[outputs,emb])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 141s 141ms/step - loss: 4.2380 - dense_19_loss: 0.5488 - flatten_13_loss: 3.6891 - dense_19_accuracy: 0.7088 - flatten_13_accuracy: 2.0000e-04 - val_loss: 3.6490 - val_dense_19_loss: 0.4205 - val_flatten_13_loss: 3.2285 - val_dense_19_accuracy: 0.8068 - val_flatten_13_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f293b712828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxPARkts8yMa"
      },
      "source": [
        " y_pred = model.predict(x_train)\n",
        " emb1 = y_pred[1][0]"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut7Zgl-a8y5N"
      },
      "source": [
        "emb1 = emb1.reshape(40,128)\n",
        "emb_looks = emb1[3]\n",
        "emb_watch = emb1[30]"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9utdH_mA81F5"
      },
      "source": [
        " emb2 = y_pred[1][7]\n",
        " emb2 = emb2.reshape(40,128)\n",
        " emb_never = emb1[7]"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9uPnls585Fx"
      },
      "source": [
        "emb1 = emb1.reshape(40,128)\n",
        "emb_amazing = emb1[5]\n",
        "emb_praised = emb1[9]"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUtyuvYD86gj",
        "outputId": "4b8c76b7-1403-4b1f-e16c-42b1897c95e8"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "d1 = distance.euclidean(emb_looks, emb_watch)\n",
        "print(d1)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8272520303726196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH1Su7ZS89EZ",
        "outputId": "537c55db-039f-47b4-d833-caba8d434321"
      },
      "source": [
        "d2 = distance.euclidean(emb_looks, emb_never)\n",
        "d2"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9193055033683777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4cy-7oh8_5b",
        "outputId": "aee89484-4fbd-4483-8828-5de4ddc0f582"
      },
      "source": [
        "d2 = distance.euclidean(emb_never, emb_watch)\n",
        "d2"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9905773401260376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    }
  ]
}